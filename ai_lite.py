# -*- coding: utf-8 -*-
"""
Created on Sun Aug 21 15:13:22 2022

@author: Josh, Mertash
"""
import numpy as np 
import os
import torch
import torchvision
from torch import nn
from torch.utils.data import DataLoader
from torch.utils.data.dataset import Dataset
from numba import vectorize, njit

unetUsed = "ai_statedict"
directory = ""

class compactDataset(Dataset):
    def __init__(self, data):
        self.images = data
        self.to_tensor = torchvision.transforms.ToTensor()
    def __getitem__(self, index):
        image = self.images[index]
        image = self.to_tensor(image)
        return image
    def __len__(self):
        return len(self.images)
    
# UNET
class UNET(nn.Module):
    def __init__(self):
        super(UNET, self).__init__()
        
        self.down1 = Unetdown(3,16,True)
        self.down2 = Unetdown(16,32,False)
        self.down3 = Unetdown(32,64,False)
        self.down4 = Unetdown(64,128,False)
        self.down5 = Unetdown(128,256,False)
        self.down6 = Unetdown(256,512,False)
        
        self.up7 = Unetup(512,256,False)
        self.up8 = Unetup(256,128,False)
        self.up9 = Unetup(128,64,False)
        self.up10 = Unetup(64,32,False)
        self.up11 = Unetup(32,16,True)
    
    def forward(self, x):
        # x = 1 x 512 x 512
        x1 = self.down1(x)
        # x1 = 16 x 512 x 512
        x2 = self.down2(x1)
        # x2 = 32 x 256 x 256
        x3 = self.down3(x2)
        # x3 = 64 x 128 x 128
        x4 = self.down4(x3)
        # x4 = 128 x 64 x 64
        x5 = self.down5(x4)
        # x5 = 256 x 32 x 32
        x6 = self.down6(x5)
        # x6 = 512 x 16 x 16
        
        x7 = self.up7(x6,x5)
        # x7 = 256 x 32 x 32
        x8 = self.up8(x7,x4)
        # x8 = 128 x 64 x 64
        x9 = self.up9(x8,x3)
        # x9 = 64 x 128 x 128
        x10 = self.up10(x9,x2)
        # x10 = 32 x 256 x 256
        x11 = self.up11(x10,x1)
        # x11 = 1 x 512 x 512
        
        return x11

class Unetdown(nn.Module):
    def __init__(self, input_nc, output_nc, first_layer = False):
        super(Unetdown, self).__init__()
        
        model = []
        if not first_layer:
            model += [nn.MaxPool2d(2)]
        
        model += [nn.Conv2d(input_nc, output_nc, 3, padding=1),
                  nn.ReLU(),
                  nn.Conv2d(output_nc, output_nc, 3, padding=1),
                  nn.ReLU()]
        
        self.model = nn.Sequential(*model)
        
    def forward(self, x):
        out = self.model(x)
        
        return out

class Unetup(nn.Module):
    def __init__(self, input_nc, output_nc, last_layer = False):
        super(Unetup, self).__init__()

        self.up= nn.ConvTranspose2d(input_nc, output_nc, 2, stride=2)
        model = []
        model += [nn.Conv2d(input_nc, output_nc, 3, padding=1),
                  nn.ReLU(),
                  nn.Conv2d(output_nc, output_nc, 3, padding=1),
                  nn.ReLU()]
        
        if last_layer:
            model += [nn.Conv2d(output_nc, 2, 1, padding=0)]
          
        self.model = nn.Sequential(*model)
            
    def forward(self, x1, x2):
        x1 = self.up(x1)
        out = self.model(torch.cat([x1,x2],dim=1))
        
        return out

    
@vectorize("float32(uint8)")
def convertImages(pixel):
    """
    pixel = pixel or image corresponding to np.uint8 from a satellite image
    
    normalises pixels in the range of -1 to 1 in the format of float32, which
    pyTorch needs to run.
    """
    return (pixel-128)/128

@njit
def find_missing_centre(image,threshold=2000):
    """
    image = 512x512 numpy array representing a satellite image
    threshold = the number of pixels (out of 10000) in the centre of the image
                for the image to be considered missing its centre.
                
    returns true or false, indicating if an image is missing its centre.
    """
    missing_found = 0
    for row in range(206,306):
        for col in range(206,306):
            if image[row,col] == 0:
                missing_found += 1
            if missing_found > threshold:
                return True
    return False

def selectionsTo3(images):
    """
    ---------------------------------------------------------------------------
    images = satellite images of TC
    labels = TC cloud labels corresponding to images
    selections = generated by manualSelect()

    Creates a set of 3D images corresponding to images before, during and after
    given times with 1.5 hourly spacing. This inheritently removes the first 
    and last 3 images provided as there is nothing before or after available for
    those images.
    ---------------------------------------------------------------------------
    """
    selections = np.ones(len(images))
    selections[:3] = False
    selections[-3:] = False
    unclears = [find_missing_centre(image) for image in images]
    imagesSelected = np.zeros((np.count_nonzero(selections),512,512,3), dtype=np.uint8)
    updatedSelections = []
    upto = 0
    for i,selection in enumerate(selections):
        if selection == 1:
            if not (unclears[i-3] or unclears[i] or unclears[i+3]):
                imagesSelected[upto]=np.dstack((images[i-3],images[i],images[i+3]))
                upto += 1
                updatedSelections.append(True)
            else:
                updatedSelections.append(False)
        else:
            updatedSelections.append(False)
        
    return imagesSelected[:upto], updatedSelections

def predict(images,verbose=False):
    """
    input = numpy array of type np.uin8, of shape (n_images,512,512) 
            where n_images >= 7 
    
    Returns a prediction of the segmentations where 1 indicates a tc pixel and 0
    indicates a non-tc pixel, this removes certain images outlined in the 
    second element in the return tuple.
    """
    if verbose:print("Arranging images...")
    images,selections = selectionsTo3(images)
    images = convertImages(images)
    predictions = []
    images = compactDataset(images)
    images = iter(DataLoader(images, batch_size = 1))
    with torch.no_grad():
        if verbose:print("Predicting...")
        for image in images:
            image = image.to(device)
            predictions.append(np.array(torch.argmax(model(image),dim=1,keepdim=True).cpu()[0,0,:,:])) 
    if verbose:print("Complete.")
    return np.array(predictions, dtype = np.uint8),selections

os.environ["CUDA_LAUNCH_BLOCKING"] = "1"
device = torch.device(0 if torch.cuda.is_available() else 'cpu')
model = UNET().to(device)
model.load_state_dict(torch.load(f"{directory}{unetUsed}.pt"))
model.eval()
params = f"{sum(p.numel() for p in model.parameters() if p.requires_grad):,} parameters"